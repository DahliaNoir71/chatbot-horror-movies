# ============================================================================
# HORRORBOT - Environment Variables Template
# ============================================================================
# Copy this file to .env and fill in the values
# E1 Validation: 5 heterogeneous sources
#   - TMDB API (REST)
#   - Rotten Tomatoes (Scraping)
#   - YouTube API (REST)
#   - Kaggle CSV (File + Spark Big Data)
# ============================================================================

# -------------------------------------------------------------------------
# TMDB API (REST API - Source 1)
# -------------------------------------------------------------------------
# Get free API key: https://www.themoviedb.org/settings/api
TMDB_API_KEY=your_tmdb_api_key_here
TMDB_BASE_URL=https://api.themoviedb.org/3
TMDB_IMAGE_BASE_URL=https://image.tmdb.org/t/p/w500
TMDB_LANGUAGE=en-US
TMDB_INCLUDE_ADULT=true
TMDB_HORROR_GENRE_ID=27
TMDB_USE_PERIOD_BATCHING=false
TMDB_YEAR_MIN=1970
TMDB_YEAR_MAX=2025
TMDB_YEARS_PER_BATCH=5
TMDB_MAX_PAGES=500
TMDB_REQUESTS_PER_PERIOD=40
TMDB_PERIOD_SECONDS=10
TMDB_MIN_REQUEST_DELAY=0.25
TMDB_CHECKPOINT_SAVE_INTERVAL=10
TMDB_ENRICH_MOVIES=true
TMDB_SAVE_CHECKPOINTS=true

# -------------------------------------------------------------------------
# Rotten Tomatoes (Web Scraping - Source 2)
# -------------------------------------------------------------------------
# No API key required (web scraping)
RT_BASE_URL=https://www.rottentomatoes.com
RT_MAX_RETRIES=3
RT_TIMEOUT=30

# -------------------------------------------------------------------------
# Kaggle API (CSV Dataset - Source 4 via Spark)
# -------------------------------------------------------------------------
# 1. Create account: https://www.kaggle.com/account/login
# 2. Generate token: https://www.kaggle.com/settings → "API" → "Create New Token"
KAGGLE_USERNAME=your_kaggle_username
KAGGLE_KEY=your_kaggle_api_key
KAGGLE_DATASET_SLUG=evangower/horror-movies

# -------------------------------------------------------------------------
# Apache Spark (Big Data Processing - C1/C2)
# -------------------------------------------------------------------------
SPARK_MASTER=local[*]
SPARK_APP_NAME=HorrorBot-ETL
SPARK_DRIVER_MEMORY=2g
SPARK_EXECUTOR_MEMORY=2g
SPARK_SHUFFLE_PARTITIONS=4

# -------------------------------------------------------------------------
# PostgreSQL - Databases (HorrorBot Docker)
# -------------------------------------------------------------------------
# Use port 5434 to avoid conflict with local PostgreSQL (5432)
POSTGRES_HOST=localhost
POSTGRES_PORT=5434
POSTGRES_DB=horrorbot
POSTGRES_VECTORS_DB=horrorbot_vectors
POSTGRES_USER=horrorbot_user
POSTGRES_PASSWORD=change_this_password_in_production

# Pool settings
DB_POOL_SIZE=5
DB_POOL_OVERFLOW=10
DB_POOL_TIMEOUT=30

# -------------------------------------------------------------------------
# API REST - FastAPI (E3)
# -------------------------------------------------------------------------
API_HOST=0.0.0.0
API_PORT=8000
API_RELOAD=true
API_WORKERS=4
API_PUBLIC_URL=http://localhost:8000

# -------------------------------------------------------------------------
# Security - JWT (E3)
# -------------------------------------------------------------------------
# Generate with: openssl rand -hex 32
JWT_SECRET_KEY=generate_a_random_secret_key_with_openssl_rand_hex_32
JWT_ALGORITHM=HS256
JWT_EXPIRE_MINUTES=30

# -------------------------------------------------------------------------
# Security - Rate Limiting (E3)
# -------------------------------------------------------------------------
RATE_LIMIT_PER_MINUTE=100
RATE_LIMIT_PER_HOUR=1000

# -------------------------------------------------------------------------
# CORS (E3)
# -------------------------------------------------------------------------
# Allowed origins (comma-separated)
CORS_ORIGINS=http://localhost:3000,http://localhost:8000,https://horrorbot.app

# -------------------------------------------------------------------------
# AI Services - LLM (E2 - C8)
# -------------------------------------------------------------------------
# Path to GGUF model file (relative to project root or absolute)
LLM_MODEL_PATH=models/qwen3-8b.Q4_K_M.gguf
# HuggingFace source for automatic download (init_models script)
LLM_HF_REPO=Qwen/Qwen3-8B-GGUF
LLM_HF_FILENAME=Qwen3-8B-Q4_K_M.gguf
LLM_CONTEXT_LENGTH=4096
LLM_MAX_TOKENS=512
LLM_TEMPERATURE=0.7
LLM_TIMEOUT_SECONDS=60
# -1 = offload all layers to GPU, 0 = CPU only
LLM_N_GPU_LAYERS=-1

# -------------------------------------------------------------------------
# AI Services - Intent Classifier (E2 - C8)
# -------------------------------------------------------------------------
CLASSIFIER_MODEL_NAME=MoritzLaurer/DeBERTa-v3-base-zeroshot-v2.0
CLASSIFIER_CONFIDENCE_THRESHOLD=0.4
# Valid: cpu, cuda, auto
CLASSIFIER_DEVICE=auto

# -------------------------------------------------------------------------
# AI Services - Embeddings (E2 - C8)
# -------------------------------------------------------------------------
EMBEDDING_MODEL_NAME=all-MiniLM-L6-v2
EMBEDDING_DIMENSIONS=384
EMBEDDING_BATCH_SIZE=64

# -------------------------------------------------------------------------
# ETL Configuration
# -------------------------------------------------------------------------
ETL_MAX_WORKERS=4
SCRAPING_DELAY=2.0
USER_AGENT=HorrorBot-ETL/1.0 (Educational Project)

# -------------------------------------------------------------------------
# Logging
# -------------------------------------------------------------------------
LOG_LEVEL=INFO
LOG_DIR=logs
LOG_FORMAT=json

# -------------------------------------------------------------------------
# Environment
# -------------------------------------------------------------------------
# Valid values: development, production, test
ENVIRONMENT=development
DEBUG=true