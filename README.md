# ğŸ¬ HorrorBot - Chatbot spÃ©cialisÃ© films d'horreur

[![Python 3.12+](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org/downloads/)
[![PostgreSQL 16](https://img.shields.io/badge/PostgreSQL-16-blue.svg)](https://www.postgresql.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

> Projet de certification **DÃ©veloppeur en Intelligence Artificielle** - Blocs E1 Ã  E5

## ğŸ“‹ Description

**HorrorBot** est un chatbot conversationnel spÃ©cialisÃ© dans les films d'horreur, utilisant une architecture **RAG** (Retrieval-Augmented Generation) pour fournir des recommandations personnalisÃ©es et rÃ©pondre aux questions des utilisateurs avec sources citÃ©es.

### Ã‰tat actuel du projet

| Bloc | Statut | Description |
|------|--------|-------------|
| **E1** | âœ… Complet | 5 sources (TMDB, RT, Kaggle, IMDB, Spark), PostgreSQL + pgvector |
| **E2** | âœ… Complet | Veille, benchmark, paramÃ©trage Qwen2.5-7B-Instruct via llama.cpp |
| **E3** | âš ï¸ Partiel | API REST, monitoring, MLOps â€” code complet, rÃ©dactionnel en cours |
| **E4** | ğŸ“… PlanifiÃ© | Frontend Vue.js/Next.js |
| **E5** | ğŸ“… PlanifiÃ© | Monitoring applicatif |

### CaractÃ©ristiques implÃ©mentÃ©es

- âœ… **Pipeline ETL multi-sources** : TMDB API, Rotten Tomatoes (scraping), Kaggle CSV, IMDB SQLite, Apache Spark
- âœ… **Base vectorielle** : PostgreSQL 16 + pgvector pour recherche sÃ©mantique
- âœ… **Embeddings** : sentence-transformers (all-MiniLM-L6-v2)
- âœ… **LLM local** : Qwen2.5-7B-Instruct (Q5_K_M) via llama-cpp-python
- âœ… **Intent Classifier** : DeBERTa-v3 zero-shot (routage intelligent des requÃªtes)
- âœ… **Pipeline RAG** : Retriever pgvector + prompt builder + LLM (Qwen2.5-7B-Instruct)
- âœ… **Chatbot conversationnel** : Endpoints `/chat` + `/chat/stream` SSE, sessions multi-turn, routage par intent
- âœ… **API REST sÃ©curisÃ©e** : FastAPI + JWT + rate limiting + CORS
- âœ… **Monitoring** : Prometheus + Grafana (21 mÃ©triques, 3 dashboards)
- âœ… **Configuration centralisÃ©e** : Pydantic Settings avec validation
- âœ… **Checkpoints** : Reprise automatique aprÃ¨s interruption
- âœ… **100% open-source** : Aucun service payant

## ğŸ—ï¸ Architecture technique

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        SOURCES DE DONNÃ‰ES                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TMDB API â”‚ Rotten Tom.  â”‚  Kaggle  â”‚ IMDB SQLite  â”‚  Apache Spark   â”‚
â”‚  (REST)  â”‚  (Scraping)  â”‚  (CSV)   â”‚   (Joins)    â”‚   (SparkSQL)    â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚             â”‚            â”‚           â”‚                â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  ETL PIPELINE  â”‚
                   â”‚ â€¢ Extraction   â”‚
                   â”‚ â€¢ AgrÃ©gation   â”‚
                   â”‚ â€¢ Validation   â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  PostgreSQL 16 â”‚
                   â”‚   + pgvector   â”‚
                   â”‚   + embeddings â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚   API FastAPI  â”‚
                   â”‚  â€¢ JWT Auth    â”‚
                   â”‚  â€¢ Rate Limit  â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  Frontend      â”‚  â† E4 (planifiÃ©)
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Installation rapide

### PrÃ©requis

- **Python 3.12+**
- **[uv](https://docs.astral.sh/uv/)** (gestionnaire de dÃ©pendances)
- **Docker & Docker Compose**
- **Git**

### Ã‰tape 1 : Cloner le repository

```bash
git clone https://github.com/DahliaNoir71/chatbot-horror-movies.git
cd chatbot-horror-movies
```

### Ã‰tape 2 : Installer uv

```bash
# Linux/Mac
curl -LsSf https://astral.sh/uv/install.sh | sh

# Windows (PowerShell)
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
```

### Ã‰tape 3 : Installer les dÃ©pendances

```bash
# DÃ©pendances core + dev (sans ML lourd)
uv sync

# Avec les dÃ©pendances ML lourdes (torch CUDA, transformers, etc.)
uv sync --group ml

# Installer les navigateurs Playwright (pour scraping RT)
uv run playwright install
```

### Ã‰tape 4 : Configuration

```bash
# Copier le template .env
cp .env.example .env

# Ã‰diter .env avec vos valeurs
```

**Variables obligatoires** :

```env
# TMDB (obtenir sur https://www.themoviedb.org/settings/api)
TMDB_API_KEY=your_api_key_here

# PostgreSQL
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=horrorbot
POSTGRES_USER=horrorbot_user
POSTGRES_PASSWORD=horrorbot_dev_password

# Extraction (optionnel)
TMDB_USE_PERIOD_BATCHING=true
TMDB_YEAR_MIN=1950
TMDB_YEAR_MAX=2025
```

### Ã‰tape 5 : DÃ©marrer PostgreSQL

```bash
docker compose up -d

# VÃ©rifier que PostgreSQL est ready
docker compose logs -f postgres
# Attendre "database system is ready to accept connections"
```

### Ã‰tape 6 : Lancer le pipeline

```bash
# Pipeline complet : ETL + Import DB
uv run python -m src full

# Ou par Ã©tapes :
uv run python -m src etl              # Extraction + enrichissement
uv run python -m src import-db        # Import en base avec embeddings
```

## ğŸ“– Commandes CLI

```bash
# Pipeline ETL complet
uv run python -m src full --max-pages 5

# ETL seul (sans import DB)
uv run python -m src etl --max-pages 5

# Reprendre depuis une Ã©tape
uv run python -m src etl --resume-from 2   # 1=TMDB, 2=RT, 3=AgrÃ©gation

# Import checkpoint en base
uv run python -m src import-db

# Lister les checkpoints
uv run python -m src list-checkpoints

# Lancer l'API
uv run uvicorn src.api.main:app --reload

# Lancer le frontend (dans un autre terminal)
uv run python -m http.server 8080 --directory src/integration/
# AccÃ¨s chatbot : http://localhost:8080
```

## ğŸ“ Structure du projet

```text
chatbot-horror-movies/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __main__.py           # CLI principal
â”‚   â”œâ”€â”€ settings/             # Configuration Pydantic (package)
â”‚   â”‚   â”œâ”€â”€ ai.py             # LLMSettings, ClassifierSettings, EmbeddingSettings
â”‚   â”‚   â”œâ”€â”€ api.py            # APISettings
â”‚   â”‚   â””â”€â”€ database.py       # DatabaseSettings
â”‚   â”œâ”€â”€ etl/
â”‚   â”‚   â”œâ”€â”€ pipeline.py       # Orchestrateur ETL
â”‚   â”‚   â”œâ”€â”€ aggregator.py     # AgrÃ©gation et validation
â”‚   â”‚   â””â”€â”€ extractors/       # Extracteurs par source
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ llm/              # LLMService (wrapper llama-cpp-python)
â”‚   â”‚   â”œâ”€â”€ intent/           # IntentClassifier + IntentRouter + prompts
â”‚   â”‚   â”œâ”€â”€ chat/             # SessionManager (multi-turn)
â”‚   â”‚   â”œâ”€â”€ rag/              # DocumentRetriever, RAGPromptBuilder, RAGPipeline
â”‚   â”‚   â””â”€â”€ embedding/        # EmbeddingService (sentence-transformers)
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”œâ”€â”€ models.py         # SQLAlchemy + pgvector
â”‚   â”‚   â””â”€â”€ repositories/     # Repositories (films, RAG)
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ main.py           # FastAPI app factory
â”‚   â”‚   â”œâ”€â”€ routers/          # Endpoints (films, auth, chat)
â”‚   â”‚   â”œâ”€â”€ schemas.py        # ModÃ¨les Pydantic
â”‚   â”‚   â””â”€â”€ dependencies/     # JWT auth, rate limiting
â”‚   â””â”€â”€ monitoring/
â”‚       â”œâ”€â”€ metrics.py        # MÃ©triques Prometheus
â”‚       â””â”€â”€ middleware.py      # PrometheusMiddleware + /metrics
â”œâ”€â”€ tests/                    # Tests pytest (seuil CI â‰¥ 50%)
â”œâ”€â”€ docs/                     # Documentation technique
â”œâ”€â”€ docker/                   # Config Prometheus, Grafana, init-db
â”œâ”€â”€ docker-compose.yml        # PostgreSQL + pgvector + monitoring
â”œâ”€â”€ pyproject.toml            # DÃ©pendances et configuration (uv)
â”œâ”€â”€ uv.lock                   # Lock file reproductible
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

## ğŸ§ª Tests

```bash
# Lancer tous les tests
uv run pytest tests/ -v

# Tests avec couverture
uv run pytest tests/ -v --cov=src --cov-report=html
```

## ğŸ“Š Statistiques actuelles

| MÃ©trique | Valeur |
|----------|--------|
| **Sources de donnÃ©es** | 5 (TMDB API, Rotten Tomatoes, Kaggle CSV, IMDB SQLite, Spark) |
| **Fichiers Python** | 149 (~23 500 lignes) |
| **Couverture tests** | â‰¥ 50% (seuil CI) |
| **Temps extraction** | ~2-3h pour 1950-2025 |

## ğŸ› ï¸ Stack technique

### Backend

- **Python 3.12** avec typage strict
- **FastAPI** + **Uvicorn** (API REST async)
- **Pydantic 2** pour validation et settings
- **SQLAlchemy 2** ORM
- **PostgreSQL 16** + **pgvector** 0.5

### IA

- **llama-cpp-python** : LLM local (Qwen2.5-7B-Instruct Q5_K_M via GGUF)
- **transformers** : Intent Classifier (DeBERTa-v3 zero-shot)
- **sentence-transformers** : Embeddings (all-MiniLM-L6-v2)

### ETL

- **requests** + **tenacity** (retry) pour TMDB
- **Crawl4AI** + **BeautifulSoup4** pour Rotten Tomatoes
- **pandas** + **polars** pour Kaggle CSV
- **SQLAlchemy** pour IMDB SQLite
- **PySpark** pour Apache Spark

### Monitoring

- **Prometheus** + **Grafana** (3 dashboards : LLM, RAG, API)
- **prometheus_client** (21 mÃ©triques)

### QualitÃ©

- **pytest** + **pytest-cov** + **pytest-benchmark**
- **Ruff** (linting + formatting), **Vulture** (dead code)
- **structlog** pour logging JSON

## ğŸ—ºï¸ Roadmap

- [x] Pipeline ETL 5 sources (TMDB, RT, Kaggle, IMDB, Spark)
- [x] Base PostgreSQL + pgvector
- [x] Embeddings sentence-transformers
- [x] API REST FastAPI (JWT, rate limiting, CORS)
- [x] IntÃ©gration LLM Qwen2.5-7B-Instruct via llama.cpp
- [x] Intent Classifier DeBERTa-v3 zero-shot
- [x] Monitoring Prometheus/Grafana (3 dashboards)
- [x] CI/CD GitHub Actions (5 jobs)
- [x] Pipeline RAG complet (retriever â†’ prompt â†’ LLM) (E3)
- [x] Endpoints chat + streaming SSE (E3)
- [x] Pipeline MLOps GitHub Actions (6 jobs : validation, Ã©valuation, rapport, livraison) (E3)
- [ ] Frontend Vue.js (E4)
- [ ] Monitoring applicatif avancÃ© (E5)

## ğŸ“„ Licence

MIT License - Voir [LICENSE](LICENSE)

## ğŸ‘¤ Auteur

**Serge PFEIFFER**  
DÃ©veloppeur en Intelligence Artificielle (en formation)

- GitHub : [@DahliaNoir71](https://github.com/DahliaNoir71)