# ğŸ¬ HorrorBot - Chatbot spÃ©cialisÃ© films d'horreur

[![Python 3.12+](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104-green.svg)](https://fastapi.tiangolo.com/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-16-blue.svg)](https://www.postgresql.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

> Projet de certification **DÃ©veloppeur en Intelligence Artificielle** - Blocs E1 Ã  E5

## ğŸ“‹ Description

**HorrorBot** est un chatbot thÃ©matique dÃ©diÃ© aux films d'horreur. Il rÃ©pond Ã  des questions factuelles, propose des recommandations personnalisÃ©es et fournit des anecdotes sourcÃ©es sur l'univers du cinÃ©ma d'horreur.

### CaractÃ©ristiques principales

- âœ… **Base de donnÃ©es exhaustive** : 142 000+ films d'horreur
- âœ… **API REST sÃ©curisÃ©e** : Authentification JWT, rate limiting
- âœ… **Pipeline ETL robuste** : 5 sources de donnÃ©es (API, scraping, CSV, PostgreSQL, Spark)
- âœ… **100% open-source** : Aucun service payant
- âœ… **ConformitÃ© RGPD** : Registre des traitements, procÃ©dures de tri

## ğŸ—ï¸ Architecture technique

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      SOURCES DE DONNÃ‰ES                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TMDB API  â”‚ Wikipediaâ”‚  CSV     â”‚PostgreSQLâ”‚  Apache Spark  â”‚
â”‚  (REST)   â”‚(Scraping)â”‚ (Kaggle) â”‚  (IMDb)  â”‚   (Parquet)    â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚           â”‚         â”‚           â”‚             â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  ETL PIPELINE  â”‚
                    â”‚ â€¢ Extraction   â”‚
                    â”‚ â€¢ AgrÃ©gation   â”‚
                    â”‚ â€¢ Nettoyage    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  PostgreSQL 16 â”‚
                    â”‚   + pgvector   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   API FastAPI  â”‚
                    â”‚  â€¢ JWT Auth    â”‚
                    â”‚  â€¢ Rate Limit  â”‚
                    â”‚  â€¢ OpenAPI     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Front Next.js â”‚
                    â”‚  (Bloc E4)     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Installation rapide

### PrÃ©requis

- **Python 3.12+**
- **PostgreSQL 16**
- **Git**
- **8 GB RAM minimum** (16 GB recommandÃ©s pour Spark)

### Ã‰tape 1 : Cloner le repository

```bash
git clone https://github.com/DahliaNoir71/chatbot-horror-movies.git
cd chatbot-horror-movies
```

### Ã‰tape 2 : CrÃ©er l'environnement virtuel

```bash
python3.12 -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows
```

### Ã‰tape 3 : Installer les dÃ©pendances

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

### Ã‰tape 4 : Configuration

```bash
# Copier le template .env
cp .env.example .env

# Ã‰diter .env et remplir les valeurs
nano .env
```

**Variables critiques Ã  configurer** :

```bash
TMDB_API_KEY=votre_cle_api_tmdb        # Obtenir sur https://www.themoviedb.org/settings/api
POSTGRES_PASSWORD=votre_mot_de_passe   # Choisir un mot de passe fort
JWT_SECRET_KEY=votre_secret_jwt        # GÃ©nÃ©rer avec : openssl rand -hex 32
```

### Ã‰tape 5 : CrÃ©er la base de donnÃ©es PostgreSQL

```bash
# CrÃ©er utilisateur et base
sudo -u postgres createuser -P horrorbot_user
sudo -u postgres createdb -O horrorbot_user horrorbot

# Installer extension pgvector
sudo apt install postgresql-16-pgvector  # Ubuntu/Debian
# ou
brew install pgvector  # macOS

# Activer l'extension
psql -h localhost -U horrorbot_user -d horrorbot -c "CREATE EXTENSION vector;"
```

### Ã‰tape 6 : CrÃ©er le schÃ©ma de base de donnÃ©es

```bash
psql -h localhost -U horrorbot_user -d horrorbot -f database/schema.sql
```

### Ã‰tape 7 : Lancer le pipeline ETL

```bash
# Extraction des donnÃ©es (durÃ©e : ~45 minutes)
python etl/main.py

# AgrÃ©gation et nettoyage (durÃ©e : ~5 minutes)
python etl/run_aggregation.py

# Import en base de donnÃ©es (durÃ©e : ~3 minutes)
python database/import_data.py
```

### Ã‰tape 8 : Lancer l'API

```bash
uvicorn api.main:app --reload --host 0.0.0.0 --port 8000
```

ğŸ‰ **L'API est accessible sur** : http://localhost:8000/docs

## ğŸ“š Documentation

- **[Installation complÃ¨te](docs/database/installation.md)** : Guide dÃ©taillÃ© pas Ã  pas
- **[Documentation API](http://localhost:8000/docs)** : Swagger UI (quand API lancÃ©e)
- **[SpÃ©cifications ETL](docs/specifications/ETL_extraction_specs.md)** : DÃ©tails techniques extraction
- **[ModÃ©lisation Merise](docs/database/merise_modeling.md)** : MCD, MLD, MPD
- **[ConformitÃ© RGPD](docs/rgpd/registre_traitements.md)** : Registre des traitements

## ğŸ§ª Tests

```bash
# Lancer tous les tests
pytest tests/ -v

# Tests avec couverture
pytest tests/ -v --cov=etl --cov=api --cov-report=html

# Tests d'intÃ©gration API
pytest tests/test_api.py -v --integration
```

## ğŸ“Š Statistiques du projet

| MÃ©trique | Valeur |
|----------|--------|
| **Films extraits** | 1 489 023 (bruts) â†’ 142 583 (nettoyÃ©s) |
| **Sources de donnÃ©es** | 5 (API, scraping, CSV, PostgreSQL, Spark) |
| **Lignes de code Python** | 2 834 lignes |
| **Lignes de code SQL** | 542 lignes |
| **Tests automatisÃ©s** | 61 tests, 87% couverture |
| **Endpoints API** | 6 endpoints REST |
| **Temps de dÃ©veloppement** | 140 heures (oct-dÃ©c 2025) |

## ğŸ› ï¸ Stack technique

### Backend
- **Langage** : Python 3.12
- **Framework API** : FastAPI 0.104
- **ORM** : SQLAlchemy 2.0
- **Base de donnÃ©es** : PostgreSQL 16 + pgvector
- **Big Data** : Apache Spark 3.5

### ETL
- **Extraction API** : requests, tenacity (retry)
- **Web scraping** : BeautifulSoup4, lxml
- **Fichiers CSV** : pandas
- **Fuzzy matching** : jellyfish (Levenshtein)

### SÃ©curitÃ©
- **Authentification** : JWT (python-jose)
- **Rate limiting** : SlowAPI
- **Validation** : Pydantic 2.4
- **Hashing** : bcrypt (passlib)

### Tests et qualitÃ©
- **Tests** : pytest, pytest-cov
- **Linting** : flake8, black, isort
- **Type checking** : mypy

## ğŸ“ Structure du projet

```
chatbot-horror-movies/
â”œâ”€â”€ api/                    # API REST FastAPI
â”‚   â”œâ”€â”€ routers/            # Endpoints (movies, auth, search)
â”‚   â”œâ”€â”€ models/             # SchÃ©mas Pydantic
â”‚   â”œâ”€â”€ security/           # JWT, rate limiting
â”‚   â””â”€â”€ main.py             # Point d'entrÃ©e API
â”œâ”€â”€ etl/                    # Pipeline ETL
â”‚   â”œâ”€â”€ extractors/         # 5 extracteurs (TMDB, Wikipedia, CSV, PostgreSQL, Spark)
â”‚   â”œâ”€â”€ main.py             # Orchestrateur ETL
â”‚   â”œâ”€â”€ aggregator.py       # AgrÃ©gation et nettoyage
â”‚   â”œâ”€â”€ config.py           # Configuration centralisÃ©e
â”‚   â””â”€â”€ utils.py            # Helpers (logging, retry, checkpoints)
â”œâ”€â”€ database/               # Base de donnÃ©es
â”‚   â”œâ”€â”€ schema.sql          # DDL PostgreSQL
â”‚   â””â”€â”€ import_data.py      # Script d'import
â”œâ”€â”€ data/                   # DonnÃ©es (gitignored)
â”‚   â”œâ”€â”€ raw/                # CSV bruts
â”‚   â”œâ”€â”€ processed/          # CSV nettoyÃ©s
â”‚   â”œâ”€â”€ checkpoints/        # JSON intermÃ©diaires
â”‚   â””â”€â”€ big_data/           # Parquet Spark
â”œâ”€â”€ docs/                   # Documentation
â”‚   â”œâ”€â”€ specifications/     # Specs ETL
â”‚   â”œâ”€â”€ database/           # Merise, installation
â”‚   â”œâ”€â”€ sql/                # RequÃªtes SQL documentÃ©es
â”‚   â”œâ”€â”€ api/                # Specs API
â”‚   â””â”€â”€ rgpd/               # Registre RGPD
â”œâ”€â”€ tests/                  # Tests automatisÃ©s
â”œâ”€â”€ logs/                   # Logs (gitignored)
â”œâ”€â”€ requirements.txt        # DÃ©pendances Python
â”œâ”€â”€ .env.example            # Template variables environnement
â””â”€â”€ README.md               # Ce fichier
```

## ğŸ¤ Contribution

Ce projet est dÃ©veloppÃ© dans le cadre d'une formation de certification. Les contributions externes ne sont pas acceptÃ©es pour le moment.

## ğŸ“„ Licence

MIT License - Voir [LICENSE](LICENSE)

## ğŸ‘¤ Auteur

**Serge PFEIFFER**  
DÃ©veloppeur en Intelligence Artificielle (en formation)

- GitHub : [@DahliaNoir71](https://github.com/DahliaNoir71)
- Email : serge.pfeiffer@example.com

## ğŸ™ Remerciements

- **TMDB** pour l'API gratuite
- **Wikipedia** pour les donnÃ©es CC-BY-SA
- **Kaggle** pour les datasets publics
- **Anthropic** pour Claude (assistance dÃ©veloppement)

---

â­ **Si ce projet vous intÃ©resse, n'hÃ©sitez pas Ã  le star sur GitHub !**